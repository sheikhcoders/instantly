{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cb5a9d0",
   "metadata": {},
   "source": [
    "# Building an Agentic RAG System with Instantly\n",
    "\n",
    "This notebook demonstrates how to build an advanced Retrieval-Augmented Generation (RAG) system using Instantly and Hugging Face's inference capabilities. RAG systems combine the power of large language models with external knowledge retrieval to produce more accurate and contextually relevant responses.\n",
    "\n",
    "## What is Agentic RAG?\n",
    "\n",
    "Agentic RAG extends traditional RAG by making the retrieval process more dynamic and intelligent:\n",
    "\n",
    "1. **Query Optimization**: The agent formulates retrieval-friendly queries\n",
    "2. **Multi-Step Retrieval**: Multiple retrievals can be performed as needed\n",
    "3. **Reasoning**: The agent analyzes and synthesizes information from multiple sources\n",
    "4. **Self-Improvement**: Can critique and refine its retrieval strategy\n",
    "\n",
    "In this notebook, we'll build a complete Agentic RAG system that can answer questions about machine learning by retrieving information from documentation and papers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816fb860",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's install and import the required dependencies. We'll use:\n",
    "- `instantly`: For interfacing with Hugging Face models\n",
    "- `langchain`: For document processing and retrieval\n",
    "- `datasets`: For loading our knowledge base\n",
    "- `python-dotenv`: For managing environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f26dde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install instantly langchain langchain-community datasets python-dotenv rank_bm25 sentence-transformers --upgrade\n",
    "\n",
    "# Import necessary packages\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from instantly import OpenAIClient\n",
    "import datasets\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Instantly client\n",
    "client = OpenAIClient(\n",
    "    base_url=\"https://router.huggingface.co/v1\",\n",
    "    api_key=os.environ[\"HF_TOKEN\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31343db8",
   "metadata": {},
   "source": [
    "## Hub API Integration\n",
    "\n",
    "The Hugging Face Hub provides powerful APIs to interact with Inference Providers. We can:\n",
    "1. List models by provider and task\n",
    "2. Check model inference status\n",
    "3. Get provider information for specific models\n",
    "\n",
    "Let's explore these capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b24f63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: List models by provider\n",
    "from huggingface_hub import list_models\n",
    "\n",
    "# List all models served by Fireworks AI\n",
    "fireworks_models = list(list_models(inference_provider=\"fireworks-ai\"))\n",
    "print(\"Fireworks AI Models:\")\n",
    "for model in fireworks_models[:5]:  # Show first 5 models\n",
    "    print(f\"- {model.id}\")\n",
    "\n",
    "# Example 2: Get model status and provider information\n",
    "from huggingface_hub import model_info\n",
    "\n",
    "# Check model status\n",
    "model_name = \"google/gemma-3-27b-it\"\n",
    "info = model_info(model_name, expand=[\"inference\", \"inferenceProviderMapping\"])\n",
    "\n",
    "print(f\"\\nModel: {model_name}\")\n",
    "print(f\"Inference Status: {info.inference}\")\n",
    "print(\"\\nProviders:\")\n",
    "for provider, mapping in info.inference_provider_mapping.items():\n",
    "    print(f\"- {provider}:\")\n",
    "    print(f\"  Status: {mapping.status}\")\n",
    "    print(f\"  Task: {mapping.task}\")\n",
    "    print(f\"  Provider ID: {mapping.provider_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52176051",
   "metadata": {},
   "source": [
    "## Knowledge Base Preparation\n",
    "\n",
    "We'll prepare our knowledge base using the Hugging Face documentation dataset. This includes:\n",
    "1. Loading the documentation\n",
    "2. Filtering to relevant content\n",
    "3. Converting to Document objects\n",
    "4. Splitting into manageable chunks"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
